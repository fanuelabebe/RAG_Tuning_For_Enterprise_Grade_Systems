{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389865e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in /home/fanuel-data/.local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/fanuel-data/miniconda3/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /home/fanuel-data/.local/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.12.25\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b375d494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# os.environ['OPENAI_API_KEY'] = api_key\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4048cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a4a3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/fanuel-data/.local/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/fanuel-data/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.12.25 tiktoken-0.5.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd00eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "811d8c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The tasks to be done for final submission are completing work for automatic prompt generation, automatic evaluation, and evaluation data generation. Additionally, a blog post entry or PDF report should be submitted for feedback and grading.\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('./week_6_challenge_doc.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=200)\n",
    "texts  = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "store = Chroma.from_documents(texts,embeddings, collection_name=\"challenge_document\")\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "chain = RetrievalQA.from_chain_type(llm,retriever=store.as_retriever())\n",
    "\n",
    "print(chain.run(\"what are the tasks to be done for final submission?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67b15ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can submit the final report in either a blog post entry (such as on Medium) or a PDF report.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"what format am i supposed to sumbit the final report?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56975014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The challenge document has 4 tasks.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"how many tasks does the challenge document have?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "632f988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The tutorial dates are Monday and Tuesday.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"can you list out the tutorial dates?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abd04ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The key performance indicators for the challenge are understanding prompt ranking, understanding prompt matching, and ability to reuse previous knowledge.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"what are the key performance indicators for the challenge?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
