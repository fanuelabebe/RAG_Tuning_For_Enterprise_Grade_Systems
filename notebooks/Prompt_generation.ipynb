{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d24cc4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# os.environ['OPENAI_API_KEY'] = api_key\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a8a637ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "594304b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "def file_reader(path: str, ) -> str:\n",
    "    fname = os.path.join(path)\n",
    "    with open(fname, 'r') as f:\n",
    "        system_message = f.read()\n",
    "    return system_message\n",
    "            \n",
    "def get_prompt():\n",
    "    prompt_message = file_reader(\"../prompts/prompt_generation_template.txt\")\n",
    "    prompt = str(prompt_message)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d20de",
   "metadata": {},
   "source": [
    "## Prompt Generator Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e7cf4ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'output'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'output'], template='Your task is to formulate exactly 5 questions from given context and provide the answer to each one.\\n\\nEnd each question with a \\'?\\' character and then in a newline write the answer to that question using only \\nthe context provided.\\nThe output MUST BE in a json format. \\n\\nexample:\\n[\\n{{\\n    \"user\": \"What is the name of the company?\",\\n    \"assistant\": \"Google\"\\n}},\\n{{\\n    \"user\": \"What is the name of the CEO?\",\\n    \"assistant\": \"Sundar Pichai\"\\n}}\\n]\\n\\nEach question must start with \"user:\".\\nEach answer must start with \"assistant:\".\\n\\n\\nThe question must satisfy the rules given below:\\n1.The question should make sense to humans even when read without the given context.\\n2.The question should be fully answered from the given context.\\n3.The question should be framed from a part of context that contains important information. It can also be from tables,code,etc.\\n4.The answer to the question should not contain any links.\\n5.The question should be of moderate difficulty.\\n6.The question must be reasonable and must be understood and responded by humans.\\n7.Do no use phrases like \\'provided context\\',etc in the question\\n8.Avoid framing question using word \"and\" that can be decomposed into more than one question.\\n10.The question should expand on what the user input is.\\n11.The Answer to the question should correspond with the output given\\n12.The Answer should align with the output\\n    \\ncontext: {context}\\n\\noutput: {output}'))])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG_PROMPT_TEMPLATE = get_prompt()\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT_TEMPLATE)\n",
    "rag_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bc8a3",
   "metadata": {},
   "source": [
    "## Embeddings and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7f6a138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('./week_6_challenge_doc.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap=200, model_name = \"gpt-4-1106-preview\")\n",
    "texts  = text_splitter.split_documents(documents)\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "store = Chroma.from_documents(texts,embeddings, collection_name=\"challenge_document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff9f70",
   "metadata": {},
   "source": [
    "## Stringoutput Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e8db8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "str_output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47bf7f",
   "metadata": {},
   "source": [
    "## Setting up RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "15e933f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "retriever = store.as_retriever()\n",
    "\n",
    "entry_point_and_retriever = RunnableParallel(\n",
    "    {\n",
    "        \"context\" : retriever,\n",
    "        \"output\" : RunnablePassthrough()\n",
    "    }\n",
    ")\n",
    "\n",
    "rag_chain = entry_point_and_retriever | rag_prompt | llm | str_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b8abae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\n[\\n{\\n    \"user\": \"What are the goals of the challenge?\",\\n    \"assistant\": \"The goal of this approach is to support and reward expertise in different parts of the Machine learning engineering toolbox.\"\\n},\\n{\\n    \"user\": \"What are the fundamental tasks for this week\\'s challenge?\",\\n    \"assistant\": \"The core tasks for this weekâ€™s challenge in Automatic Prompt Engineering are outlined below.\"\\n},\\n{\\n    \"user\": \"What is the task 1 about?\",\\n    \"assistant\": \"Task 1: Review the Evolution of Automatic Prompt Engineering.\"\\n},\\n{\\n    \"user\": \"What are the key developments in the field of automatic prompt engineering?\",\\n    \"assistant\": \"Focus on understanding the key developments in the field of automatic prompt engineering for Language Models (LLMs).\"\\n},\\n{\\n    \"user\": \"What is the purpose of the badges?\",\\n    \"assistant\": \"In addition to being the badge holder for that badge, each badge winner will get +20 points to the overall score.\"\\n}\\n]'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('i want to know the goals of the challenge')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
